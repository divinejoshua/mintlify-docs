---
title: 'Chat with Collection'
description: 'Learn how to converse with your collections in WetroCloud'
---
The `chat` endpoint allows you to converse with your collection allowing it to respond based on information from your resources added to the collection via the WetroCloud API.  

### Required Parameters
| Field               | Description                                          |
|---------------------|------------------------------------------------------|
| `collection_id`     | Collection Id.                                       |
| `message`           | Message currently being sent to collection           |
| `chat_history`      | History of chat between user and system              |
| `stream` (optional) | Enable stream responses for long-form content.       |

### Request Example
<CodeGroup>
    ```python Python
        from wetro import Wetrocloud

        client = Wetrocloud(api_key="your_api_key")
        rag_client = client.rag
        rag_client.collection.get_or_create_collection_id("my_unique_collection_id")
        insert_response = rag_client.collection.insert("https://medium.com/@wetrocloud/why-legal-tech-needs-wetrocloud-ai-rag-and-the-future-of-legal-practice-66fb38c4df09", "web")
        print("Insert response: %s", insert_response)

        # Create a chat history or set it to [] (empty list)
        chat_history = [
            {"role": "user", "content": "What is this collection about?"}, 
            {"role": "system", "content": "It stores research papers on AI technology."}
        ]

        # Continue the conversation with context
        chat_response = rag_client.collection.chat(
            "Can you explain the latest paper's methodology?",
            chat_history
        )
        print(chat_response)

        # Stream responses for long-form content
        chat_response = rag_client.collection.chat(
            "Can you explain the latest paper's methodology?",
            chat_history,
            stream=True
        )
        # Process streaming response
        for chunk in chat_response:
            print(chunk.response, end="")
    ```
    ```bash cURL
    curl --request POST \
        --url https://api.wetrocloud.com/v1/collection/chat/ \
        --header 'Authorization: Token <api-key>' \
        --header 'Content-Type: multipart/form-data' \
        --form 'collection_id=<collection_id>' \
        --form 'message=Tell me more' \
        --form 'chat_history=[{"role":"user","content":"What is this all about?"}, {"role":"system","content":"This is about Queen Elizabeth_II of England"}]' \
    ```
    ```javascript JavaScript
    const axios = require('axios');
    const FormData = require('form-data');

    const url = 'https://api.wetrocloud.com/v1/collection/query/';
    const formData = new FormData();
    formData.append('collection_id', '<collection_id>');
    formData.append('message', 'Tell me more');
    formData.append('chat_history', [{"role":"user",  "content":"What is this all about?"}, 
        {"role":"system","content":"This is about Queen Elizabeth_II of England"}]);

    const headers = {
        'Authorization': 'Token <api-key>',
        ...formData.getHeaders()
    };

    axios.post(url, formData, { headers })
        .then(response => console.log(response.data))
        .catch(error => console.error(error));
    ```
</CodeGroup> 

---

### Response Example:

```json
{
  "response": "The sales for Q1 increased by 20% compared to last year, with online channels contributing significantly.",
  "tokens": 120,
  "success": true
}
```

| Field     | Description                                           |
|-----------|-------------------------------------------------------|
| `response` | Conversational response to the message.                |
| `tokens`   | Number of tokens used for processing.                |
| `success`  | Indicates whether the query was successful.          |