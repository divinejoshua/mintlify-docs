---
title: 'Chat with Collection'
description: 'Learn how to converse with your collections using the Wetrocloud SDK'
---

Use the `chat` method from the `collection` module to converse with your collection. The collection will respond based on information from your indexed resources.

### Required Parameters
| Field               | Description                                          |
|---------------------|------------------------------------------------------|
| `collection_id`     | Unique identifier for the collection                 |
| `message`           | Message to send to the collection                    |
| `chat_history`      | List of previous messages between user and system    |
| `stream` (optional) | Enable stream responses for long-form content        |

### Regular Chat Request
<CodeGroup>
```python Python
from wetro import Wetrocloud

# Access Module
client = Wetrocloud(api_key="your_api_key")
rag_client = client.rag

# Create a collection
rag_client.create_collection(collection_id="research_paper")

# Insert a web resource
insert_response = rag_client.collection.insert_resource(
    collection_id="research_paper",
    resource="https://medium.com/@wetrocloud/why-legal-tech-needs-wetrocloud-ai-rag-and-the-future-of-legal-practice-66fb38c4df09", 
    type="web"
)

# Create a chat history
chat_history = [
    {"role": "user", "content": "What is this collection about?"}, 
    {"role": "system", "content": "It stores research papers on AI technology."}
]

# Continue the conversation with context
chat_response = rag_client.collection.chat(
    collection_id="research_papers",
    message="Can you explain the latest paper's methodology?",
    chat_history=chat_history
)
print(chat_response)
    ```
    ```bash cURL
    curl --request POST \
        --url https://api.wetrocloud.com/v1/collection/chat/ \
        --header 'Authorization: Token <api-key>' \
        --header 'Content-Type: multipart/form-data' \
        --form 'collection_id=research_papers' \
        --form 'message=Tell me more' \
        --form 'chat_history=[{"role":"user","content":"What is this all about?"}, {"role":"system","content":"This is about research papers"}]'
    ```
    ```javascript JavaScript
    const axios = require('axios');
    const FormData = require('form-data');

    const url = 'https://api.wetrocloud.com/v1/collection/chat/';
    const formData = new FormData();
    formData.append('collection_id', 'research_papers');
    formData.append('message', 'Tell me more');
    formData.append('chat_history', JSON.stringify([
        {"role":"user", "content":"What is this all about?"}, 
        {"role":"system", "content":"This is about research papers"}
    ]));

    const headers = {
        'Authorization': 'Token <api-key>',
        ...formData.getHeaders()
    };

    axios.post(url, formData, { headers })
        .then(response => console.log(response.data))
        .catch(error => console.error(error));
    ```
</CodeGroup> 

### Streaming Chat Request

For long-form responses, you can enable streaming to receive content chunks as they're generated.

<CodeGroup>
```python Python
# Stream responses for long-form content
stream_response = rag_client.collection.chat(
    collection_id="research_papers",
    message="Can you explain the latest paper's methodology?",
    chat_history=chat_history,
    stream=True
)

# Process streaming response
for chunk in stream_response:
    print(chunk.response, end="")
```
</CodeGroup>

### Response Types

#### Regular Response
```json
{
  "response": "Based on the latest paper's methodology...",
  "tokens": 120,
  "success": true
}
```

| Field      | Description                                    |
|------------|------------------------------------------------|
| `response` | The collection's answer to your message        |
| `tokens`   | Number of tokens used in processing            |
| `success`  | Indicates if the operation was successful      |
| `done`     | (Stream only) Indicates if stream is complete  |