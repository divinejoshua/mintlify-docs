---
title: 'Query your Collection'
description: 'Learn how to query your collections in WetroCloud for both free text and structured responses.'
---

The `query` endpoint allows you to retrieve information from a collection (your resources) via the WetroCloud API.  
This endpoint supports two response formats to suit different use cases:  

- **Free Text Response**: A natural language answer to your query.  
- **Structured Output Response**: A structured JSON output.

Each response type has unique request and response formats, which are explained in detail on their respective pages.  

## Required Parameters

| Field               | Description                                          |
|---------------------|------------------------------------------------------|
| `collection_id`     | Collection Id.                                       |
| `query`             | This is the prompt.                                  |
| `model` (optional)  | Pass in the model you want.                          |
| `stream` (optional) | Enable stream responses for long-form content.       |

## Free Text Response

Free text response provides natural, conversational-style answers to your queries. It is ideal for general Q&A and scenarios where a narrative or contextualized explanation is needed. Unlike structured output, free text does not require additional parameters like `json_schema` and `json_schema_rules`.

### Request Example

<CodeGroup>
  ```python Python
  from wetro import Wetrocloud

  # Access Module
  client = Wetrocloud(api_key="your_api_key")
  rag_client = client.rag

  # Create a collection
  rag_client.create_collection("my_unique_collection_id")

  # Insert a resource into the collection
  insert_response = rag_client.collection.insert_resource(
    collection_id="my_unique_collection_id",
    resource="https://medium.com/@wetrocloud/why-legal-tech-needs-wetrocloud-ai-rag-and-the-future-of-legal-practice-66fb38c4df09",
    type="web"
  )

  # Query the collection
  query_response = rag_client.collection.query_collection(
    collection_id="my_unique_collection_id",
    request_query="What are the key points of the article?"
  )

  print(query_response)
  ```
  ```bash cURL
  curl --request POST \
    --url https://api.wetrocloud.com/v1/collection/query/ \
    --header 'Authorization: Token <api-key>' \
    --header 'Content-Type: application/json' \
    --data '{
      "collection_id": "<collection_id>",
      "request_query": "What are the sales trends for Q1?"
    }'
  ```
  ```javascript JavaScript
  const axios = require('axios');

  const apiKey = '<api-key>';
  const collectionId = '<collection_id>';
  const query = 'What are the sales trends for Q1?';

  const requestData = {
    collection_id: collectionId,
    request_query: query
  };

  axios.post('https://api.wetrocloud.com/v1/collection/query/', requestData, {
    headers: {
      'Authorization': `Token ${apiKey}`,
      'Content-Type': 'application/json'
    }
  })
  .then(response => {
    console.log('Response:', response.data);
  })
  .catch(error => {
    console.error('Error:', error.response ? error.response.data : error.message);
  });
  ```
</CodeGroup>

## Query a Collection with a Custom LLM

To get a response from a specific model, you can define the model in your query request.

```python
# Define Model to get response from the specific model
model_response = rag_client.collection.query_collection(
  request_query="Give me a detailed summary of the article",
  collection_id="my_unique_collection_id",
  model="gpt-3.5-turbo"
)
print(model_response)
```

## Stream Responses for Long-Form Content

For long-form content, you can enable streaming responses by setting the `stream` flag to `true`.

```python
# Stream responses for long-form content
streaming_response = rag_client.collection.query_response(
    collection_id="research_papers",
    request_query = "Give me a detailed summary of the article",
    stream=True
)

# Process streaming response
for chunk in streaming_response:
    print(chunk.response, end="")

```

## Response Example: Free Text

```json
{
  "response": "The sales for Q1 increased by 20% compared to last year, with online channels contributing significantly.",
  "tokens": 120,
  "success": true
}
```

| Field      | Description                                           |
|------------|-------------------------------------------------------|
| `response` | Conversational response to the query.                |
| `tokens`   | Number of tokens used for processing.                |
| `success`  | Indicates whether the query was successful.          |