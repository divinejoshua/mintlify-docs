---
title: 'Supported Models'
description: 'WetroCloud currently supports the following models:'
---
## **Meta Models**  
Meta develops the Llama series of models, which are high-performance, open-weight large language models optimized for various use cases, including chat and code generation.  

| Model Name               | Identifier                  | Description |
|--------------------------|----------------------------|-------------|
| llama-3.3-70b-specdec    | llama-3.3-70b-specdec      | Specialized decoding variant of Llama 3.3 (70B). |
| llama-3.3-70b-versatile  | llama-3.3-70b-versatile    | Versatile version of Llama 3.3 (70B) for various tasks. |
| llama-3.3-70b           | llama-3.3-70b              | Standard Llama 3.3 model with 70B parameters. |
| llama-3.2-90b-vision-preview | llama-3.2-90b-vision-preview | Vision-enabled variant of Llama 3.2 (90B). |
| llama-3.2-11b-vision-preview | llama-3.2-11b-vision-preview | Smaller vision-based variant of Llama 3.2 (11B). |
| llama-3.2-3b-preview    | llama-3.2-3b-preview       | Preview version of Llama 3.2 with 3B parameters. |
| llama-3.2-1b-preview    | llama-3.2-1b-preview       | Lightweight preview of Llama 3.2 (1B parameters). |
| llama-3.1-8b-instant    | llama-3.1-8b-instant       | Faster and optimized variant of Llama 3.1 (8B). |
| llama-3.1-8b           | llama-3.1-8b              | Standard Llama 3.1 model with 8B parameters. |
| llama3-70b-8192        | llama3-70b-8192           | Llama 3 variant with 70B parameters and 8192 token context. |
| llama3-8b-8192         | llama3-8b-8192            | Llama 3 variant with 8B parameters and 8192 token context. |
| llama-guard-3-8b       | llama-guard-3-8b          | A specialized Llama 3.3 model focused on content moderation. |

---

## **Mistral Models**  
Mistral specializes in efficient, state-of-the-art transformer models designed for high-speed inference and strong performance.  

| Model Name            | Identifier             | Description |
|-----------------------|-----------------------|-------------|
| mixtral-8x7b-32768   | mixtral-8x7b-32768    | A mixture-of-experts model with 8x7B experts and a 32K token context. |

---

## **DeepSeek Models**  
DeepSeek focuses on developing cutting-edge language models with optimized performance for reasoning and efficiency.  

| Model Name                            | Identifier                            | Description |
|---------------------------------------|---------------------------------------|-------------|
| deepseek-r1-distill-qwen-32b          | deepseek-r1-distill-qwen-32b         | Distilled version of Qwen-32B optimized by DeepSeek. |
| deepseek-r1-distill-llama-70b-specdec | deepseek-r1-distill-llama-70b-specdec | Distilled version of Llama 70B with specialized decoding. |
| deepseek-r1-distill-llama-70b         | deepseek-r1-distill-llama-70b        | Distilled Llama 70B model with improved efficiency. |

---

## **Alibaba Qwen Models**  
Qwen, developed by Alibaba, is designed for code and general-purpose NLP tasks, with a focus on efficiency and accuracy.  

| Model Name             | Identifier            | Description |
|------------------------|----------------------|-------------|
| qwen-2.5-coder-32b    | qwen-2.5-coder-32b   | A 32B parameter model optimized for code generation. |
| qwen-2.5-32b          | qwen-2.5-32b         | A 32B parameter model optimized for various NLP tasks. |

---

## **Anthropic Models**  
Anthropic develops the Claude series of AI models, focusing on safety, interpretability, and human-like responses.  

| Model Name                   | Identifier                   | Description |
|------------------------------|-----------------------------|-------------|
| claude-3-7-sonnet-20250219   | claude-3-7-sonnet-20250219  | Latest Claude 3.7 Sonnet model, optimized for balanced performance. |
| claude-3-5-sonnet-20241022   | claude-3-5-sonnet-20241022  | Improved version of Claude 3.5 Sonnet. |
| claude-3-5-haiku-20241022    | claude-3-5-haiku-20241022   | Lightweight and fast Claude 3.5 Haiku model. |
| claude-3-5-sonnet-20240620   | claude-3-5-sonnet-20240620  | Earlier version of Claude 3.5 Sonnet. |
| claude-3-opus-20240229       | claude-3-opus-20240229      | Most powerful Claude 3 model for advanced reasoning. |
| claude-3-sonnet-20240229     | claude-3-sonnet-20240229    | Claude 3 Sonnet model with strong performance. |
| claude-3-haiku-20240307      | claude-3-haiku-20240307     | Fastest Claude 3 model for quick responses. |

---

## **OpenAI Models**  
OpenAI develops the GPT series, including GPT-4o and GPT-4, designed for high-performance natural language understanding and generation.  

| Model Name                      | Identifier                      | Description |
|---------------------------------|--------------------------------|-------------|
| gpt-4.5-preview                 | gpt-4.5-preview               | Latest GPT-4o model for creative tasks and agentic planning. |
| gpt-4o-latest                  | chatgpt-4o-latest              | Latest iteration of GPT-4o with enhanced features. |
| gpt-4o-mini                    | gpt-4o-mini                    | A lightweight version of GPT-4o optimized for efficiency. |
| gpt-4o                         | gpt-4o                         | Standard GPT-4o model with top-tier performance. |
| gpt-4-turbo-preview            | gpt-4-turbo-preview            | A preview of the turbocharged GPT-4 model. |
| gpt-4-turbo                    | gpt-4-turbo                    | Faster and cheaper variant of GPT-4. |
| gpt-4                           | gpt-4                           | Standard GPT-4 model with strong reasoning capabilities. |
| gpt-3.5-turbo                   | gpt-3.5-turbo                   | An efficient version of GPT-3.5 with strong performance. |
| o3-mini                        | o3-mini                        | Optimized small-scale model for fast inference. |
| o1-mini                        | o1-mini                        | Mini variant of OpenAI’s "o1" model. |
| o1                             | o1                             | Standard version of OpenAI’s "o1" model. |
| o1-preview                     | o1-preview                     | Preview version of OpenAI’s "o1" model. |

<Note> These are the language models support at the moment, please use the identifiers above not the model name. </Note>

# Models Usage
You can use these models in our [Query endpoint](/endpoint-explanations/query) and [OpenAI Compatibility endpoints](/endpoint-explanations/openai-compatibility)
### Query Endpoint Example 
<CodeGroup>
```bash cURL
curl --request POST \
  --url https://api.wetrocloud.com/v1/collection/query/ \
  --header 'Authorization: Token <api-key>' \
  --header 'Content-Type: application/json' \
  --data '{
    "collection_id": "<collection_id>",
    "request_query": "What are the sales trends for Q1?",
    "model": "claude-3-7-sonnet-20250219"
  }'
```
```python Python
import requests

url = "https://api.wetrocloud.com/v1/collection/query/"
headers = {
    "Authorization": "Token <api-key>",
    "Content-Type": "application/json"
}
data = {
    "collection_id": "<collection_id>",
    "request_query": "What are the sales trends for Q1?",
    "model": "claude-3-7-sonnet-20250219"
}

response = requests.post(url, headers=headers, json=data)
print(response.json())
```
```javascript JavaScript
const axios = require('axios');

const apiKey = '<api-key>';
const collectionId = '<collection_id>';
const query = 'What are the sales trends for Q1?';
const model = 'claude-3-7-sonnet-20250219';

const requestData = {
  collection_id: collectionId,
  request_query: query
  model: model
};

axios.post('https://api.wetrocloud.com/v1/collection/query/', requestData, {
  headers: {
    'Authorization': `Token ${apiKey}`,
    'Content-Type': 'application/json'
  }
})
.then(response => {
  console.log('Response:', response.data);
})
.catch(error => {
  console.error('Error:', error.response ? error.response.data : error.message);
});

```
</CodeGroup>

